{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from collections import defaultdict \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from  torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = './flickr8/Images'\n",
    "CAPTIONS_PATH = './flickr8/captions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/tyler.kobil/Desktop/code/DL/venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlickrDataset(Dataset):\n",
    "    def __init__(self, captions_path, images_path, transform=transforms.ToTensor()):\n",
    "        self.tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "        self.img_caption_dict = self._load_img_caption_dict(captions_path)\n",
    "        self.caption_vocab = self._get_vocab(self.img_caption_dict)\n",
    "        self.image_paths = [f\"{images_path}/{img_name}\" for img_name in self.img_caption_dict.keys()]\n",
    "        self.image_captions = list(self.img_caption_dict.values())\n",
    "        self.transform = transform\n",
    "        \n",
    "    def _get_vocab(self, img_caption_dict):\n",
    "        counter = Counter()\n",
    "        for img_key in img_caption_dict:\n",
    "            for caption in img_caption_dict[img_key]:\n",
    "                counter.update(self.tokenizer(caption))\n",
    "        caption_vocab = vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "        caption_vocab.lookup_token(100)\n",
    "        caption_vocab.set_default_index(caption_vocab[\"<unk>\"])\n",
    "        return caption_vocab\n",
    "    \n",
    "    def _load_img_caption_dict(self, captions_path):\n",
    "        img_capt_dict = defaultdict(list)\n",
    "        with open(captions_path, 'r') as captions_file:\n",
    "            for line in captions_file.readlines():\n",
    "                if line.startswith(\"image\"):\n",
    "                    # header\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    current_line = line.split(',')\n",
    "                    img = current_line[0]\n",
    "                    capt = current_line[1]\n",
    "                    img_capt_dict[img].append(capt)\n",
    "                    \n",
    "        return img_capt_dict        \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_caption_dict)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index]).convert(\"RGB\")\n",
    "        image_tensor = self.transform(image)\n",
    "        \n",
    "        data = []\n",
    "        for caption in self.image_captions[index]:\n",
    "            tokens = self.tokenizer(caption)\n",
    "            tensor = torch.cat([\n",
    "                torch.tensor([self.caption_vocab['<bos>']]),\n",
    "                torch.tensor([self.caption_vocab[token] for token in tokens]),\n",
    "                torch.tensor([self.caption_vocab['<eos>']])\n",
    "            ])\n",
    "            data.append(tensor)\n",
    "                \n",
    "        \n",
    "        return image_tensor, pad_sequence(data, padding_value=self.caption_vocab['<pad>'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FlickrDataset(CAPTIONS_PATH, IMAGES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__getitem__(5)[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        imgs = [item[0].unsqueeze(0) for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n",
    "\n",
    "        return imgs, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    collate_fn=Collate(pad_idx=dataset.caption_vocab['<pad>']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/image_captioning/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size, train=False):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.use_pretrained = not train\n",
    "        inception = models.inception_v3(pretrained=self.use_pretrained, aux_logits=False)\n",
    "        inception.fc = nn.Linear(self.inception.fc.in_features, embed_size)\n",
    "        # make sure output of cnn model is embed size\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            inception,\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.main(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        embeddings = self.dropout(self.embed(captions))\n",
    "        embeddings = torch.cat((features.unsqueeze(0), embeddings), dim=0)\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNtoRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(CNNtoRNN, self).__init__()\n",
    "        self.encoder = EncoderCNN(embed_size)\n",
    "        self.decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        features = self.encoder(images)\n",
    "        outputs = self.decoder(features, captions)\n",
    "        return outputs\n",
    "\n",
    "    def caption_image(self, image, vocabulary, max_length=50):\n",
    "        result_caption = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded_image = self.encoder(image).unsqueeze(0)\n",
    "            states = None\n",
    "\n",
    "            for _ in range(max_length):\n",
    "                hiddens, states = self.decoder.lstm(encoded_image, states)\n",
    "                output = self.decoder.linear(hiddens.squeeze(0))\n",
    "                predicted = output.argmax(1)\n",
    "                predicted_word = vocabulary.itos[predicted.item()]\n",
    "                result_caption.append(predicted_word)\n",
    "                encoded_image = self.decoder.embed(predicted).unsqueeze(0)\n",
    "\n",
    "                if predicted_word == \"<EOS>\":\n",
    "                    break\n",
    "\n",
    "        return result_caption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
