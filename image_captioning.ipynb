{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from collections import defaultdict \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch\n",
    "from  torchtext.vocab import vocab\n",
    "from torchtext.data.utils import get_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = './flickr8/Images'\n",
    "CAPTIONS_PATH = './flickr8/captions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img_caption_dict():\n",
    "    img_capt_dict = defaultdict(list)\n",
    "    with open(CAPTIONS_PATH, 'r') as captions_file:\n",
    "        for line in captions_file.readlines():\n",
    "            if line.startswith(\"image\"):\n",
    "                # header\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                current_line = line.split(',')\n",
    "                img = current_line[0]\n",
    "                capt = current_line[1]\n",
    "                img_capt_dict[img].append(capt)\n",
    "    return img_capt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "counter = Counter()\n",
    "img_caption_dict = load_img_caption_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A child in a pink dress is climbing up a set of stairs in an entry way .\\n',\n",
       " 'A girl going into a wooden building .\\n',\n",
       " 'A little girl climbing into a wooden playhouse .\\n',\n",
       " 'A little girl climbing the stairs to her playhouse .\\n',\n",
       " 'A little girl in a pink dress going into a wooden cabin .\\n']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_caption_dict['1000268201_693b08cb0e.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9020\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "for img_key in img_caption_dict:\n",
    "    for caption in img_caption_dict[img_key]:\n",
    "        counter.update(tokenizer(caption))\n",
    "        \n",
    "\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_vocab = vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "caption_vocab.lookup_token(100)\n",
    "caption_vocab.set_default_index(caption_vocab[\"<unk>\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1000268201_693b08cb0e.jpg',\n",
       " tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12,  7, 13, 14, 15,  6, 16, 17, 18, 19,\n",
       "         20]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer(img_caption_dict[list(img_caption_dict.keys())[0]])\n",
    "caption_vocab[tokenizer(img_caption_dict[list(img_caption_dict.keys())[0]][0])[0]]\n",
    "\n",
    "\n",
    "data = []\n",
    "for img_key in img_caption_dict:\n",
    "    for caption in img_caption_dict[img_key]:\n",
    "        tokens = tokenizer(caption)\n",
    "        tensor = torch.tensor([caption_vocab[token] for token in tokens], dtype=torch.long)\n",
    "        # TODO - load image data instead of using image key\n",
    "        data.append((img_key, tensor))\n",
    "\n",
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
